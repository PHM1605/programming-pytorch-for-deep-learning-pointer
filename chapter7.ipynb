{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2b165f-5c5d-44b0-b794-dac8126840a1",
   "metadata": {},
   "source": [
    "# Debugging Pytorch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcb8152-b8a8-4017-b30d-b52816666681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer.add_scalar(\"example\", 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a8de25-d197-4a34-82b7-6ac806a57a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "value = 10\n",
    "writer.add_scalar(\"test_loop\", value, 0)\n",
    "for i in range(1,10000):\n",
    "    value += random.random() - 0.5\n",
    "    writer.add_scalar(\"test_loop\", value, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1cbc3-d0b1-4935-abf7-01e8f006aebb",
   "metadata": {},
   "source": [
    "## Visualizing Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace81eba-281b-4128-a3e8-fb12418a2278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PHM16\\anaconda3\\envs\\python310\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PHM16\\anaconda3\\envs\\python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms, models \n",
    "\n",
    "writer = SummaryWriter()\n",
    "model = models.resnet18(False)\n",
    "writer.add_graph(model, torch.rand([1,3,224,224]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b2b359-e2d1-44c5-a6f0-de4ec7f51ad4",
   "metadata": {},
   "source": [
    "## Pytorch hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4486d721-ff24-4427-aa63-2c2fb86ca44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :  ResNet\n",
      "conv1 :  Conv2d\n",
      "bn1 :  BatchNorm2d\n",
      "relu :  ReLU\n",
      "maxpool :  MaxPool2d\n",
      "layer1 :  Sequential\n",
      "layer1.0 :  BasicBlock\n",
      "layer1.0.conv1 :  Conv2d\n",
      "layer1.0.bn1 :  BatchNorm2d\n",
      "layer1.0.relu :  ReLU\n",
      "layer1.0.conv2 :  Conv2d\n",
      "layer1.0.bn2 :  BatchNorm2d\n",
      "layer1.1 :  BasicBlock\n",
      "layer1.1.conv1 :  Conv2d\n",
      "layer1.1.bn1 :  BatchNorm2d\n",
      "layer1.1.relu :  ReLU\n",
      "layer1.1.conv2 :  Conv2d\n",
      "layer1.1.bn2 :  BatchNorm2d\n",
      "layer2 :  Sequential\n",
      "layer2.0 :  BasicBlock\n",
      "layer2.0.conv1 :  Conv2d\n",
      "layer2.0.bn1 :  BatchNorm2d\n",
      "layer2.0.relu :  ReLU\n",
      "layer2.0.conv2 :  Conv2d\n",
      "layer2.0.bn2 :  BatchNorm2d\n",
      "layer2.0.downsample :  Sequential\n",
      "layer2.0.downsample.0 :  Conv2d\n",
      "layer2.0.downsample.1 :  BatchNorm2d\n",
      "layer2.1 :  BasicBlock\n",
      "layer2.1.conv1 :  Conv2d\n",
      "layer2.1.bn1 :  BatchNorm2d\n",
      "layer2.1.relu :  ReLU\n",
      "layer2.1.conv2 :  Conv2d\n",
      "layer2.1.bn2 :  BatchNorm2d\n",
      "layer3 :  Sequential\n",
      "layer3.0 :  BasicBlock\n",
      "layer3.0.conv1 :  Conv2d\n",
      "layer3.0.bn1 :  BatchNorm2d\n",
      "layer3.0.relu :  ReLU\n",
      "layer3.0.conv2 :  Conv2d\n",
      "layer3.0.bn2 :  BatchNorm2d\n",
      "layer3.0.downsample :  Sequential\n",
      "layer3.0.downsample.0 :  Conv2d\n",
      "layer3.0.downsample.1 :  BatchNorm2d\n",
      "layer3.1 :  BasicBlock\n",
      "layer3.1.conv1 :  Conv2d\n",
      "layer3.1.bn1 :  BatchNorm2d\n",
      "layer3.1.relu :  ReLU\n",
      "layer3.1.conv2 :  Conv2d\n",
      "layer3.1.bn2 :  BatchNorm2d\n",
      "layer4 :  Sequential\n",
      "layer4.0 :  BasicBlock\n",
      "layer4.0.conv1 :  Conv2d\n",
      "layer4.0.bn1 :  BatchNorm2d\n",
      "layer4.0.relu :  ReLU\n",
      "layer4.0.conv2 :  Conv2d\n",
      "layer4.0.bn2 :  BatchNorm2d\n",
      "layer4.0.downsample :  Sequential\n",
      "layer4.0.downsample.0 :  Conv2d\n",
      "layer4.0.downsample.1 :  BatchNorm2d\n",
      "layer4.1 :  BasicBlock\n",
      "layer4.1.conv1 :  Conv2d\n",
      "layer4.1.bn1 :  BatchNorm2d\n",
      "layer4.1.relu :  ReLU\n",
      "layer4.1.conv2 :  Conv2d\n",
      "layer4.1.bn2 :  BatchNorm2d\n",
      "avgpool :  AdaptiveAvgPool2d\n",
      "fc :  Linear\n",
      "Shape of input is torch.Size([1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1201e-01, -3.3220e-01, -4.3342e-01,  1.6710e-01,  1.8900e-01,\n",
       "         -2.6166e-01,  7.7308e-02, -7.7550e-02, -3.9189e-01, -6.6190e-01,\n",
       "         -3.1226e-01, -1.0462e-01,  7.6775e-01, -3.5520e-01, -8.7061e-01,\n",
       "         -8.5244e-01, -3.3240e-02, -4.5212e-01,  6.1402e-01,  2.8499e-01,\n",
       "         -3.8119e-02,  2.1955e-01,  1.1794e-01, -4.9315e-01,  4.5624e-01,\n",
       "          2.7205e-02, -1.5360e-01,  2.0879e-01, -8.6651e-01,  9.2366e-02,\n",
       "          2.6604e-01,  7.7118e-01, -6.6005e-01,  1.6184e-01,  2.2298e-01,\n",
       "         -7.1495e-01,  1.3548e-01,  2.3535e-02, -7.9252e-01,  1.9291e-01,\n",
       "          2.6193e-02,  1.2149e+00,  8.8927e-02, -2.6923e-01, -1.5191e-01,\n",
       "          5.1223e-01,  1.3379e-01,  2.8660e-01, -4.8421e-01,  6.4196e-01,\n",
       "          3.7064e-02, -4.2430e-01,  9.0923e-01, -3.4581e-02, -4.8811e-01,\n",
       "         -5.2825e-01,  2.9669e-02, -4.0871e-01, -3.9158e-01,  3.5068e-01,\n",
       "         -4.5269e-01,  1.7131e-01, -2.6052e-01,  1.7699e+00, -2.6055e-01,\n",
       "          5.1670e-01,  6.6476e-01,  1.4761e-01, -5.0390e-02,  1.3448e+00,\n",
       "         -1.3119e-02, -9.1892e-01, -3.5992e-01,  1.0477e+00, -1.4252e-01,\n",
       "         -2.7557e-01, -7.0267e-01,  2.8310e-01, -1.2465e+00, -6.6867e-01,\n",
       "          6.3930e-01, -3.1061e-01, -4.9654e-01, -6.6571e-02,  1.1614e-01,\n",
       "          3.1768e-01, -4.0064e-01, -1.3420e-01, -5.0232e-01,  1.6065e-01,\n",
       "         -2.8361e-01,  2.2742e-01, -1.5086e+00,  2.9198e-01, -2.4850e-01,\n",
       "         -5.2324e-01,  2.5648e-01, -1.7582e-01,  1.4458e-01,  5.7679e-01,\n",
       "         -6.1035e-01,  1.2085e-01, -4.4705e-01,  3.0782e-01, -4.7685e-01,\n",
       "          1.0775e+00, -4.0670e-01,  5.0111e-01,  2.6376e-01,  4.4338e-01,\n",
       "          4.7242e-01, -4.5826e-01, -1.6528e-01,  7.1822e-01,  2.7482e-01,\n",
       "         -4.7609e-01, -3.6665e-02, -8.5118e-01, -2.5208e-01,  3.5703e-01,\n",
       "         -2.5520e-01,  2.6449e-01, -3.7184e-02,  3.3845e-01,  3.0744e-01,\n",
       "          2.2662e-01, -4.0335e-01, -9.4279e-02,  4.7897e-02,  3.9862e-01,\n",
       "          3.6769e-01,  1.7915e-01,  7.8250e-01, -9.6592e-01,  3.3547e-01,\n",
       "         -3.0946e-01, -4.5674e-01, -2.2483e-01, -4.3946e-02, -6.4608e-01,\n",
       "         -5.2545e-01, -6.1876e-01,  3.9791e-01,  7.1484e-01, -2.6643e-01,\n",
       "         -6.6087e-01,  3.6857e-01, -1.3146e-01,  4.3986e-01, -4.7978e-01,\n",
       "         -5.7865e-01,  4.8633e-01,  7.0158e-02, -3.3241e-01, -4.6050e-01,\n",
       "          9.1786e-01,  6.3289e-02, -8.8290e-01, -5.4348e-01,  4.6008e-01,\n",
       "          8.5683e-02,  9.1173e-01,  7.6358e-01,  7.0093e-01, -1.1748e+00,\n",
       "         -5.0201e-01,  2.9385e-02, -4.7804e-01,  1.6084e-01,  2.2068e-01,\n",
       "         -2.2757e-01,  6.4554e-01, -1.0024e+00,  5.8740e-01,  2.6136e-01,\n",
       "         -4.7150e-01,  1.4271e-01,  4.4447e-01, -4.6318e-01,  4.7207e-01,\n",
       "          5.6596e-01, -1.3931e-01, -1.0101e+00,  6.3672e-01, -1.9144e-01,\n",
       "         -1.2026e+00, -3.6889e-01, -6.4321e-01,  1.1571e-01, -1.5061e-01,\n",
       "          9.6492e-01, -3.4611e-01, -3.6873e-02,  5.0190e-01, -4.2862e-01,\n",
       "         -3.5442e-01,  4.1705e-01,  1.5045e-01,  2.0349e-01, -3.7405e-01,\n",
       "          1.4310e-01, -1.6791e-01, -1.0097e-01,  3.6769e-01, -5.1658e-01,\n",
       "          6.5376e-01, -1.0784e+00,  1.3832e-01,  4.0045e-01,  3.6089e-01,\n",
       "         -1.0094e+00, -6.9291e-01, -2.2781e-01, -9.5885e-02,  4.3395e-01,\n",
       "          9.8048e-03, -1.7020e-02, -6.5864e-01,  4.0656e-01, -7.1280e-01,\n",
       "         -4.6429e-01,  6.4300e-01,  1.7304e-01,  2.2654e-01, -4.0847e-01,\n",
       "          4.3613e-01, -9.6431e-01,  3.2663e-02,  4.0023e-01,  2.3122e-01,\n",
       "         -8.1460e-01, -2.0317e-01, -2.4931e-01, -2.0126e-01,  1.8117e-01,\n",
       "          6.2841e-01, -5.1248e-01, -2.7408e-01,  3.5925e-01, -1.0550e+00,\n",
       "          2.7790e-01,  6.5928e-02,  2.9955e-03,  5.6496e-01, -4.0142e-01,\n",
       "         -1.3487e-01, -2.5578e-01, -9.4070e-03, -3.1303e-01, -1.1835e+00,\n",
       "          9.8696e-01, -2.6012e-01, -3.7527e-01,  6.1322e-03, -7.6781e-02,\n",
       "         -8.7404e-01,  6.0266e-01,  3.0189e-02, -3.0114e-01, -5.1940e-02,\n",
       "          5.7447e-01,  4.7647e-02,  1.2545e+00, -3.5098e-01,  3.9229e-01,\n",
       "         -3.9152e-01, -3.3747e-01, -3.4972e-01,  5.2672e-01, -9.6670e-01,\n",
       "         -7.8494e-02,  5.5093e-01,  3.5137e-01, -7.0944e-01,  4.1106e-01,\n",
       "          4.6001e-01, -9.6413e-02,  3.7164e-02,  2.8326e-01, -5.6881e-01,\n",
       "         -2.7369e-01,  5.0510e-02,  2.9941e-01,  6.3592e-01, -5.8969e-01,\n",
       "          1.1816e-01,  7.5624e-02, -4.4572e-01, -1.5574e-01, -5.0336e-01,\n",
       "          3.6627e-01,  3.7817e-01, -1.3948e-02, -1.8910e-01, -4.2594e-01,\n",
       "          5.1780e-01,  2.5914e-02,  1.3114e-01,  4.4757e-01, -1.7707e-01,\n",
       "          6.5384e-01, -5.6595e-01, -5.8750e-01,  1.6084e-01,  7.7063e-01,\n",
       "         -4.9955e-02, -4.0400e-01, -8.2895e-01,  6.3310e-01, -6.0247e-01,\n",
       "         -3.4825e-01, -5.6688e-01, -3.3455e-02, -5.1654e-01, -4.2108e-01,\n",
       "         -3.9593e-01,  7.0520e-02,  6.7452e-01, -5.6434e-01,  7.5832e-01,\n",
       "         -1.3901e-01, -2.4888e-02,  2.0490e-01,  5.9740e-01, -4.9678e-02,\n",
       "          2.2891e-01, -6.9072e-02,  4.6371e-01,  6.7860e-01, -8.4901e-02,\n",
       "          5.9836e-01,  4.1195e-01, -1.7008e-01,  2.4954e-01, -2.3017e-01,\n",
       "          7.4846e-01, -3.4995e-01, -1.6542e-01,  2.5467e-01, -5.2695e-01,\n",
       "         -2.8200e-01, -1.1927e-01,  3.3723e-01,  3.6032e-01, -4.6001e-01,\n",
       "          4.7614e-02,  6.1744e-02,  3.1141e-01,  1.8623e-01,  4.0098e-01,\n",
       "          7.8487e-01, -4.7388e-01, -4.8202e-01,  8.1990e-01,  6.6766e-02,\n",
       "         -1.5536e-02, -3.5637e-01,  8.7343e-02,  3.0708e-01, -4.7594e-01,\n",
       "          4.9339e-01, -7.4973e-01, -7.2042e-02,  7.6153e-01, -1.7732e-02,\n",
       "         -4.5064e-01, -1.2224e-01,  3.3609e-02,  1.0222e-01, -7.4112e-01,\n",
       "          2.2886e-01,  4.1549e-01, -6.4909e-01, -4.2965e-01,  5.1676e-01,\n",
       "         -1.7331e-01, -5.1929e-02, -3.6493e-02, -4.0760e-02,  3.9179e-01,\n",
       "          1.2435e+00,  2.3867e-01, -5.8428e-02,  1.1755e+00, -2.8437e-02,\n",
       "          2.8454e-01,  6.3370e-01, -1.0658e-01,  1.1723e-01, -4.7128e-01,\n",
       "          6.1047e-01,  9.4513e-01,  1.0455e-01, -6.5617e-01, -5.4183e-01,\n",
       "          1.0729e+00, -4.2157e-01,  4.9002e-01, -1.1642e+00, -5.7721e-01,\n",
       "          6.7065e-02,  5.1387e-01,  5.0993e-01,  6.1969e-02,  1.6545e-01,\n",
       "          4.7625e-01,  5.3500e-01, -3.5005e-01,  3.7032e-03,  7.7722e-01,\n",
       "          1.8993e-01, -4.3502e-01, -6.7092e-01,  5.3094e-01,  7.4982e-01,\n",
       "          1.5224e-01, -1.8718e-01,  1.0845e+00,  1.6156e-01,  1.0694e+00,\n",
       "          1.7132e-01,  2.4697e-01,  1.2038e-01, -2.2893e-01,  7.7593e-01,\n",
       "          3.8899e-01, -5.6387e-02, -2.4094e-01,  4.1082e-01, -3.6922e-01,\n",
       "          3.5274e-01, -3.2801e-01, -1.6835e-01,  5.4506e-01, -1.9734e-01,\n",
       "         -4.5186e-01, -5.7274e-01, -3.4384e-01,  5.7713e-01, -1.4768e-01,\n",
       "         -2.2399e-01,  3.2731e-02,  2.7643e-01,  3.4322e-01,  4.2208e-01,\n",
       "         -3.5336e-01,  3.8197e-01, -3.1480e-01,  4.8347e-01,  6.9381e-01,\n",
       "         -2.8530e-01,  1.1926e+00,  2.1300e-01,  3.0750e-01, -2.6651e-01,\n",
       "         -2.0355e-02, -1.1722e-01, -3.1223e-01,  4.7887e-01,  6.2546e-02,\n",
       "          2.7006e-01,  5.7638e-01,  4.5707e-01,  2.1531e-01, -1.6417e-01,\n",
       "         -5.0955e-01, -6.7717e-01, -4.8849e-01,  1.6932e-02, -8.7885e-01,\n",
       "         -4.6531e-01, -1.4523e-02,  1.1771e-01, -9.0325e-02,  3.0339e-01,\n",
       "         -1.8396e-01,  2.7930e-02, -1.6624e-01, -5.4247e-01,  7.9120e-01,\n",
       "          4.9043e-03, -2.3440e-01,  6.1530e-01,  7.1011e-01,  9.3327e-02,\n",
       "         -7.5925e-01,  3.3653e-01,  1.1490e-01, -2.9066e-02, -4.2092e-01,\n",
       "         -6.1006e-01, -1.9975e-01, -8.9702e-01,  7.6507e-01,  4.3961e-01,\n",
       "          8.3674e-01, -1.5396e-01, -4.9365e-01,  5.6181e-01, -4.1574e-01,\n",
       "         -2.3612e-01,  7.4691e-01,  5.5051e-01,  1.1962e-01, -1.8443e-01,\n",
       "          4.9085e-01,  6.4597e-01,  1.0881e-01, -3.5711e-01, -7.7169e-01,\n",
       "         -5.8250e-01,  4.6371e-01,  1.7411e-01, -2.8242e-01,  1.1886e-01,\n",
       "         -1.2826e-01, -1.4599e-02, -1.6188e-01,  1.7379e-01,  2.9395e-01,\n",
       "          2.6101e-02,  2.1527e-01,  4.9836e-01,  1.6647e-02, -1.8146e-01,\n",
       "          1.6011e-01, -2.0684e-01,  6.1183e-02, -1.5233e-01, -3.1232e-01,\n",
       "         -4.9421e-02, -1.3073e-01, -6.3901e-01, -1.9327e-01,  4.1254e-01,\n",
       "         -1.6061e-01, -3.4467e-01,  3.3836e-01, -6.8544e-01, -4.4712e-01,\n",
       "         -2.4278e-01, -5.2758e-01, -5.2468e-01, -4.6959e-01, -4.6521e-01,\n",
       "          3.6482e-01,  4.3267e-01, -2.0750e-01,  5.6510e-01,  3.6708e-01,\n",
       "          4.6229e-01, -4.6298e-01, -3.8181e-01,  2.5524e-01,  6.7760e-02,\n",
       "         -2.5803e-01, -4.6139e-01, -9.9872e-01, -5.0959e-01, -2.2756e-01,\n",
       "          8.6427e-02,  2.3087e-01,  5.8005e-01, -1.8355e-01, -2.3436e-01,\n",
       "         -3.7904e-01,  1.8988e-01,  9.1770e-01,  6.2766e-01, -1.1787e-01,\n",
       "         -1.7492e-01,  5.6754e-01, -6.6073e-01,  4.1415e-01, -5.1090e-01,\n",
       "         -7.9073e-01,  1.3379e-01,  6.3463e-01, -6.8027e-02, -6.2094e-01,\n",
       "          2.7196e-01,  9.5932e-01, -2.8520e-01,  3.9482e-01, -2.1196e-01,\n",
       "         -3.8424e-01,  1.1175e+00,  1.0636e+00, -5.1972e-02,  2.2752e-01,\n",
       "         -4.8674e-01,  2.1905e-01, -1.4787e-01,  3.2448e-01, -1.3584e+00,\n",
       "          3.3646e-01, -2.9781e-01,  4.0069e-01, -7.7557e-01, -5.2106e-01,\n",
       "         -5.5772e-01,  7.1459e-01, -1.6040e-01, -2.6074e-01,  3.8039e-01,\n",
       "          9.2216e-01, -1.9969e-01, -2.5337e-01,  1.3049e+00, -7.7387e-02,\n",
       "          1.6082e-01,  8.0179e-01,  2.0210e-03,  5.5238e-01, -5.5498e-01,\n",
       "          1.5416e-01,  3.8752e-01, -4.6452e-01,  1.1453e-01,  2.3726e-01,\n",
       "         -7.1380e-01,  5.5581e-01, -2.5268e-01,  6.8647e-01,  4.9646e-01,\n",
       "         -5.6685e-02,  9.7411e-01,  7.3633e-02, -4.2471e-01, -1.3471e-01,\n",
       "          1.0287e+00,  3.1226e-01,  2.3107e-01,  1.2863e-01, -1.3870e-01,\n",
       "          7.6083e-01,  4.0833e-01, -4.1785e-01,  2.3481e-03, -4.3379e-01,\n",
       "          1.3367e-01,  5.3400e-01,  2.0986e-01, -8.6688e-01, -2.3959e-01,\n",
       "         -8.2878e-01, -2.4424e-02, -2.8828e-01, -6.2511e-01,  2.7199e-01,\n",
       "         -3.0020e-02,  1.3235e-01, -5.1299e-02, -2.0328e-02,  6.0056e-01,\n",
       "         -5.2084e-01, -2.2006e-01,  4.9136e-01, -8.2320e-01, -6.1092e-02,\n",
       "         -6.6165e-01,  1.5019e-01, -4.6740e-01,  5.9457e-01,  2.9073e-02,\n",
       "         -3.8676e-01, -1.3204e-01, -5.9274e-01, -3.2153e-01, -4.9053e-01,\n",
       "         -2.1182e-01,  6.8738e-01, -9.0446e-02,  2.4494e-01,  2.0628e-03,\n",
       "          4.2128e-01, -7.1731e-01, -7.8147e-01, -2.5453e-01, -4.2051e-01,\n",
       "         -6.8743e-01, -6.6184e-02, -9.8311e-02,  6.0179e-01, -7.0940e-01,\n",
       "          5.1498e-01,  2.5294e-01,  1.5588e+00, -7.2435e-01, -1.4502e-01,\n",
       "         -9.0271e-01, -1.9787e-01, -1.5476e-01, -4.7434e-01,  2.7561e-01,\n",
       "          1.0873e+00, -3.6216e-01,  1.4640e-02,  1.0369e+00, -9.3439e-02,\n",
       "         -5.8735e-01, -4.9523e-01, -9.1220e-01,  5.5892e-01,  3.7344e-01,\n",
       "          5.7563e-01, -2.8539e-01, -1.1075e-01,  1.7656e+00,  3.5462e-01,\n",
       "          6.1038e-01,  2.5695e-01, -2.9164e-01,  4.1845e-01,  3.3812e-01,\n",
       "          1.4168e-01,  1.8249e-01,  3.6092e-02, -2.9211e-01,  4.1043e-02,\n",
       "         -1.1610e+00, -6.8392e-01, -4.5232e-02,  7.1222e-01,  3.9680e-01,\n",
       "          4.3237e-01, -6.7427e-01,  4.8052e-02, -3.4945e-01,  3.1898e-01,\n",
       "          1.2579e+00,  1.3312e-01, -3.0268e-01,  4.0024e-01,  1.3301e-01,\n",
       "          9.3887e-02, -3.6850e-01, -4.0537e-01,  5.4760e-02,  1.0902e-01,\n",
       "         -1.3514e-01,  5.3746e-01, -5.0468e-01, -7.3078e-01, -7.2708e-01,\n",
       "         -2.5443e-01,  9.4678e-02,  1.4420e-02, -7.3193e-01, -1.1873e-01,\n",
       "         -3.2576e-03, -3.3876e-01,  1.0383e+00,  5.5582e-01,  2.8820e-01,\n",
       "          1.6044e-01,  6.2280e-02, -4.6917e-02,  3.1447e-01,  7.9016e-01,\n",
       "          7.2764e-01, -6.0386e-01,  5.4666e-03, -1.6224e-01,  4.7379e-01,\n",
       "         -1.4110e-01, -2.8759e-01, -9.7676e-01, -6.6804e-01, -2.5872e-01,\n",
       "         -7.0525e-02, -3.6773e-01,  8.2923e-01, -3.1619e-01, -4.3020e-01,\n",
       "         -1.6211e-03, -1.1469e-01,  4.1347e-01,  5.4011e-01, -6.2989e-01,\n",
       "         -4.6694e-01, -4.0640e-01, -5.2227e-01, -9.3299e-01, -4.4690e-01,\n",
       "          5.8877e-01, -5.6646e-01,  1.3966e-01,  6.4838e-01, -3.9568e-02,\n",
       "          1.6989e-01,  3.6607e-01,  1.5122e-02,  4.8489e-01,  5.4169e-01,\n",
       "         -1.8213e-02,  1.4632e-01,  8.1065e-02,  4.1037e-02, -6.4093e-01,\n",
       "          4.3601e-01, -2.7237e-01,  7.7151e-01, -3.4530e-01, -3.0624e-01,\n",
       "         -4.2391e-02, -4.0205e-01,  4.8794e-01,  1.9595e-01,  4.3816e-01,\n",
       "         -5.0654e-01, -1.2510e-02, -1.7965e-01,  1.5345e-01,  8.5226e-02,\n",
       "         -4.0417e-01,  9.6605e-02,  1.0241e+00, -4.5313e-01, -2.5797e-01,\n",
       "         -6.9091e-01,  6.3185e-01, -5.8158e-01, -4.9888e-01, -1.5054e-01,\n",
       "          1.0300e-01, -5.7793e-01,  4.4508e-01, -2.9039e-01,  5.8421e-02,\n",
       "         -2.0804e-01, -5.0465e-01, -2.2697e-01,  1.9850e-01, -4.8862e-01,\n",
       "         -3.8474e-01,  1.5827e-01, -2.5756e-01, -2.8114e-01, -3.2161e-01,\n",
       "          2.6204e-01, -7.7677e-02, -1.0590e-01, -4.8495e-01, -4.5427e-01,\n",
       "          5.4383e-01,  5.5220e-01, -3.6428e-01,  2.9317e-01,  4.3577e-01,\n",
       "         -1.3785e-01, -7.1889e-01, -1.2745e-03, -1.0696e+00, -3.5518e-01,\n",
       "          6.6763e-02, -1.0025e+00, -4.6595e-02,  4.6467e-01,  4.9729e-01,\n",
       "          6.0891e-01, -2.2051e-01, -3.8530e-01,  8.2657e-01, -3.1394e-01,\n",
       "         -8.6740e-01, -1.5707e-01,  1.2167e-01,  6.2873e-01,  7.3757e-01,\n",
       "         -9.0201e-01, -2.3739e-01,  2.2106e-01,  9.2593e-01,  4.8943e-02,\n",
       "         -7.9577e-01,  3.6150e-01, -4.2289e-01,  1.2468e+00,  2.2268e-01,\n",
       "         -4.1790e-01, -5.6108e-01,  5.7113e-01, -4.1283e-01,  2.0509e-01,\n",
       "         -1.7733e-01,  4.7966e-01, -9.0555e-01,  7.9443e-02,  3.7565e-01,\n",
       "          7.9013e-02,  6.4615e-01,  3.2467e-02, -3.1603e-01, -7.1122e-02,\n",
       "         -3.3757e-01, -1.2760e+00,  2.5206e-01, -1.7968e-01,  9.4462e-02,\n",
       "          1.6407e-01,  1.2601e+00, -3.0146e-01, -4.5729e-01,  2.8309e-01,\n",
       "         -3.4707e-01,  3.7768e-01,  1.7073e-01, -4.3584e-01,  2.0385e-01,\n",
       "          1.3531e-01, -2.9752e-01,  6.2005e-01, -1.1727e-01,  7.2884e-01,\n",
       "          1.8574e-01, -1.3238e-01,  4.3716e-01,  7.8693e-01, -1.4717e-01,\n",
       "          8.4883e-01,  6.8610e-01, -4.2063e-01, -8.2266e-01,  4.1513e-01,\n",
       "          9.2818e-01,  5.0963e-01,  3.1627e-01,  1.5709e-01,  1.0071e+00,\n",
       "         -3.2247e-01,  2.6982e-01,  9.7909e-01,  5.2401e-01,  3.5603e-02,\n",
       "         -3.0289e-01,  6.1665e-01, -8.9657e-02,  1.3522e+00, -3.8667e-01,\n",
       "          2.3446e-01, -8.4626e-01,  8.1670e-01, -5.3651e-01, -5.3054e-03,\n",
       "         -6.3562e-02, -2.4849e-02, -8.9147e-01,  3.4579e-01,  1.0411e-01,\n",
       "          4.9625e-01,  8.8312e-01, -2.7170e-01, -4.8887e-01,  7.0035e-01,\n",
       "          6.0694e-01,  3.3561e-01, -6.4121e-01,  2.0008e-02, -6.0311e-01,\n",
       "         -1.7327e-01, -1.4405e-01,  5.8379e-01,  2.5786e-01,  7.4892e-01,\n",
       "          2.5105e-02,  7.4669e-03,  3.1750e-01, -2.8728e-01, -3.8045e-01,\n",
       "         -4.5069e-02, -2.7789e-01,  9.0794e-01, -4.4457e-01, -1.5254e-01,\n",
       "          2.1619e-01, -3.8495e-02, -3.8938e-01,  2.7301e-01,  1.3697e-01,\n",
       "          5.3730e-01,  6.0656e-01,  1.3829e-02, -1.1587e+00,  1.2087e+00,\n",
       "          1.1663e-01,  4.4655e-01, -4.9715e-01, -8.5112e-02, -8.9816e-01,\n",
       "          7.1908e-02,  2.0261e-01,  1.1540e-01, -4.8502e-02, -2.5092e-01,\n",
       "         -6.4156e-01,  2.0464e-01,  2.6013e-01,  1.3166e-01, -4.2261e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_hook(module, input, output):\n",
    "    print(f\"Shape of input is {input[0].shape}\")\n",
    "model = models.resnet18()\n",
    "# to know which module inside <model>, in this case we will see <fc>\n",
    "for name, module in model.named_modules():\n",
    "    print(name, \": \", type(module).__name__)\n",
    "\n",
    "hook_ref = model.fc.register_forward_hook(print_hook)\n",
    "model(torch.rand([1,3,224,224]))\n",
    "hook_ref.remove()\n",
    "model(torch.rand([1,3,224,224]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2ec24d-288d-45c6-a59d-fa9e1f7929a2",
   "metadata": {},
   "source": [
    "### Plotting mean and std"
   ]
  },
  {
   "cell_type": "raw",
   "id": "062fbbc2-4ada-4771-9aa0-999c5b182810",
   "metadata": {},
   "source": [
    "tensorboard --logdir runs/act_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffeefd90-55a6-4f57-af7b-2a52b62ba1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with device  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PHM16\\anaconda3\\envs\\python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\PHM16\\anaconda3\\envs\\python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torchvision import models\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from functools import partial\n",
    "\n",
    "# Setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Running with device \", device)\n",
    "writer = SummaryWriter(log_dir=\"runs/act_stream\")\n",
    "model = models.resnet18(pretrained=False).to(device)\n",
    "\n",
    "# record step during TRAINING only\n",
    "train_step = {\"value\": 0}\n",
    "\n",
    "# Every time a model is run, send e.g. conv2d/mean; conv2d/std; fc/mean; fc/std... info to Tensorboard\n",
    "def send_stats(name, get_step, module, inp, out):\n",
    "    # log only during training passes\n",
    "    if not module.training:\n",
    "        return\n",
    "    if isinstance(out, (tuple, list)):\n",
    "        out = out[0]\n",
    "    if not torch.is_tensor(out):\n",
    "        return\n",
    "    out = out.detach() \n",
    "    step = get_step()\n",
    "    writer.add_scalar(f\"activations/train/{name}-mean\", out.mean().item(), step)\n",
    "    writer.add_scalar(f\"activations/train/{name}-std\", out.std().item(), step)\n",
    "# use <partial> to pass function with arguments\n",
    "hooks = []\n",
    "for name, m in model.named_modules():\n",
    "    hooks.append(m.register_forward_hook(partial(send_stats, name, lambda: train_step[\"value\"])))\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, test_loader, epochs=2):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            # advance step once per batch\n",
    "            train_step[\"value\"] += 1\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs) # hooks fire here (training=True)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            writer.add_scalar(\"train/loss\", loss.item(), train_step[\"value\"])\n",
    "            \n",
    "        model.eval()\n",
    "        num_correct = 0\n",
    "        num_examples = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                \n",
    "                num_correct += (preds==targets).sum().item()\n",
    "                num_examples += targets.size(0)\n",
    "        acc = num_correct/num_examples if num_examples else 0.0\n",
    "        print(f\"Epoch {epoch+1}, accuracy={acc:.3f}\")\n",
    "        writer.add_scalar(\"val/accuracy\", acc, train_step[\"value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57a35cce-f84a-48c8-873d-0786f437fc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, accuracy=0.000\n",
      "Epoch 2, accuracy=0.000\n"
     ]
    }
   ],
   "source": [
    "# Dummy training data\n",
    "Xtr = torch.randn(64,3,224,224); ytr = torch.randint(0,100,(64,))\n",
    "Xva = torch.randn(16,3,224,224); yva = torch.randint(0,100,(16,))\n",
    "train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(Xva, yva), batch_size=8)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train(model, optimizer, loss_fn, train_loader, val_loader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf5eb35-7b52-4fd8-8813-3a76e21a8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in hooks:\n",
    "    h.remove()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed403ee-b29e-4251-a5e9-1c322321a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
